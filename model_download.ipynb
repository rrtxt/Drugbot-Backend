{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import torch\n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from sentence_transformers import CrossEncoder\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_id = \"distiluse-base-multilingual-cased-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_id, cache_folder=\"./model_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_id = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "\n",
    "reranker = CrossEncoder(model_name=reranker_id, cache_dir=\"./model_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_2 = HuggingFaceCrossEncoder(model_name=reranker_id, model_kwargs={'cache_dir' : \"./model_cache\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not load model meta-llama/Llama-3.2-1B-Instruct with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>). See the original errors:\n\nwhile loading with AutoModelForCausalLM, an error is thrown:\nTraceback (most recent call last):\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 291, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 571, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 279, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4400, in from_pretrained\n    ) = cls._load_pretrained_model(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4818, in _load_pretrained_model\n    state_dict = load_state_dict(\n                 ^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 513, in load_state_dict\n    with safe_open(checkpoint_file, framework=\"pt\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: The paging file is too small for this operation to complete. (os error 1455)\n\nwhile loading with LlamaForCausalLM, an error is thrown:\nTraceback (most recent call last):\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 291, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 279, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4289, in from_pretrained\n    with safe_open(checkpoint_files[0], framework=\"pt\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: The paging file is too small for this operation to complete. (os error 1455)\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model_id = \u001b[33m\"\u001b[39m\u001b[33mmeta-llama/Llama-3.2-1B-Instruct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pipe = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcache_dir\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./model_cache\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:942\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    941\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    952\u001b[39m model_config = model.config\n\u001b[32m    953\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:304\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback.items():\n\u001b[32m    303\u001b[39m             error += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    305\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m         )\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    309\u001b[39m     framework = infer_framework(model.\u001b[34m__class__\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Could not load model meta-llama/Llama-3.2-1B-Instruct with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>). See the original errors:\n\nwhile loading with AutoModelForCausalLM, an error is thrown:\nTraceback (most recent call last):\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 291, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 571, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 279, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4400, in from_pretrained\n    ) = cls._load_pretrained_model(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4818, in _load_pretrained_model\n    state_dict = load_state_dict(\n                 ^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 513, in load_state_dict\n    with safe_open(checkpoint_file, framework=\"pt\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: The paging file is too small for this operation to complete. (os error 1455)\n\nwhile loading with LlamaForCausalLM, an error is thrown:\nTraceback (most recent call last):\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 291, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 279, in _wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Tugas\\SMT 7\\Skripsi\\Scripts\\DrugsBot\\drugbot-backend\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4289, in from_pretrained\n    with safe_open(checkpoint_files[0], framework=\"pt\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nOSError: The paging file is too small for this operation to complete. (os error 1455)\n\n\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    model_kwargs={'cache_dir' : './model_cache'},\n",
    "    max_new_tokens=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography?\n",
      "\n",
      "Answer: Let's think step by step. Electroencephalography (EEG) is a diagnostic tool that records the electrical activity of the brain. This is done using electrodes placed on the scalp to capture the brain's electrical signals. These signals are typically measured in terms of their frequency, amplitude, and synchronization, which can be used to diagnose and monitor various neurological conditions.\n",
      "\n",
      "Step 1: Identify the main purpose of EEG\n",
      "The main purpose of EEG is to record the electrical activity of the brain.\n",
      "\n",
      "Step 2: Consider the types of signals recorded by EEG\n",
      "EEG records various types of signals, including:\n",
      "- Brain waves: delta, theta, alpha, beta, and theta-4 wave activity.\n",
      "- Cortical activity: local field potentials and synchronized neural activity.\n",
      "- Transient activity: spike and wave discharges.\n",
      "\n",
      "Step 3: Analyze the applications of EEG\n",
      "EEG has a wide range of applications, including:\n",
      "- Diagnosing and monitoring neurological conditions such as epilepsy, seizures, and brain tumors.\n",
      "- Monitoring the effects of brain stimulation and neurosurgery.\n",
      "- Studying the effects of brain injury and disease.\n",
      "\n",
      "Step 4: Summarize the key features of EEG\n",
      "EEG is a non-invasive diagnostic tool that records the electrical activity of the brain. It is commonly\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = tavily_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Obat bpom untuk diabetes',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'Ini 5 Rekomendasi Obat Diabetes untuk Menurunkan Gula Darah ... - Halodoc',\n",
       "   'url': 'https://www.halodoc.com/artikel/ini-5-rekomendasi-obat-diabetes-untuk-menurunkan-gula-darah-tinggi',\n",
       "   'content': 'No registrasi BPOM: DKI2164605043A1. Kisaran harga: Rp2.671.100 per pen. ... Jenis Obat Diabetes untuk Menurunkan Gula Darah Tinggi. Penting untuk diingat, penggunaan obat-obatan berikut harus sesuai dengan resep dokter. Tujuannya agar dosisnya tepat dan sesuai dengan kondisi tubuh.',\n",
       "   'score': 0.5726516,\n",
       "   'raw_content': None},\n",
       "  {'title': '9 Jenis Obat Diabetes yang Umum Diresepkan Dokter - Hello Sehat',\n",
       "   'url': 'https://hellosehat.com/diabetes/obat-diabetes/',\n",
       "   'content': 'Secara umum, golongan obat diabetes memiliki cara kerja dan efek samping yang berbeda. Namun, fungsinya tetap sama, yaitu membantu mengendalikan kadar gula darah sekaligus menekan risiko komplikasi penyakit kencing manis. Berikut ini adalah beberapa golongan obat untuk diabetes yang biasanya direkomendasikan dokter. 1. Metformin (biguanid)',\n",
       "   'score': 0.40147716,\n",
       "   'raw_content': None},\n",
       "  {'title': '15 Obat Diabetes yang Umum Diresepkan Oleh Dokter - Farmaku.com',\n",
       "   'url': 'https://www.farmaku.com/artikel/obat-diabetes-yang-umum-diresepkan-oleh-dokter/',\n",
       "   'content': 'Demikian beberapa obat diabetes yang dapat ditemukan di apotek. Obat diabetes umumnya merupakan obat yang termasuk dalam golongan obat keras, sehingga perlu konsultasi dengan dokter untuk menggunakannya. Sebelum membeli obat, Anda dapat melakukan konsultasi dengan dokter rekanan Farmaku di link ini: Chat Dokter, download aplikasi Farmaku sekarang!',\n",
       "   'score': 0.2500378,\n",
       "   'raw_content': None},\n",
       "  {'title': '7 Obat Diabetes yang Manjur Turunkan Gula Darah Tinggi',\n",
       "   'url': 'https://www.alodokter.com/7-obat-diabetes-yang-manjur-turunkan-gula-darah-tinggi',\n",
       "   'content': 'Beberapa obat diabetes di atas bisa Anda konsumsi untuk mengontrol kadar gula darah, tetapi tetap sesuai petunjuk dokter. Agar kadar gula darah terkendali, Anda perlu mengonsumsi makanan bergizi lengkap dan seimbang yang rendah gula dan lemak, memperbanyak makan buah, sayur, dan biji-bijian, serta rutin berolahraga.',\n",
       "   'score': 0.2382935,\n",
       "   'raw_content': None},\n",
       "  {'title': '15 Obat Diabetes Paling Ampuh di Apotik - K24Klik',\n",
       "   'url': 'https://www.k24klik.com/blog/obat-diabetes/',\n",
       "   'content': 'Tak heran, semakin banyak obat diabetes yang diproduksi untuk memnuhi kebutuhan ini. Secara garis besar, obat diabetes dibagi menjadi beberapa kelompok obat. Selain itu, beberapa herbal pun bisa Anda gunakan untuk mencegah diabetes secara alami. Nah, berikut ini adalah rekomendasi diabetes yang bisa ditemukan di K24Klik.',\n",
       "   'score': 0.21865308,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.57}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    ")\n",
    "\n",
    "tool.invoke({\"query\": \"Obat bpom untuk diabetes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
